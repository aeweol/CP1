{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_LABELS = 9\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Programming\\anaconda3\\envs\\c_project\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 files belonging to 9 classes.\n",
      "Using 360 files for training.\n",
      "Found 450 files belonging to 9 classes.\n",
      "Using 90 files for validation.\n",
      "Found 450 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Load_Data import load_image_dataset_from_directory\n",
    "\n",
    "# filepaths\n",
    "b_dir = '/datasets/small_datasets/coffee'\n",
    "#b_dir = '/datasets/rock_paper_scissor_original'\n",
    "tr_dir = '/train'\n",
    "val_dir = '/train'\n",
    "ts_dir = '/test'\n",
    "\n",
    "# loading data\n",
    "train_dataset, valid_dataset, test_dataset = load_image_dataset_from_directory(b_dir, tr_dir, val_dir, ts_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model(VGG19+SPP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spatial_Pyramid_Pooling(https://arxiv.org/abs/1406.4729) code is provided by yhenon(https://github.com/yhenon/keras-spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd()+'/sppnet')\n",
    "from SpatialPyramidPooling import SpatialPyramidPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Normalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Normalization())\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(SpatialPyramidPooling([1,2,4]))\n",
    "    #model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4096, activation='relu', ))\n",
    "    model.add(Dense(units=4096, activation='relu', input_shape=(None,4096) ))\n",
    "    model.add(Dense(units=NUM_OF_LABELS, activation='softmax', input_shape=(None,4096) ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 2198.9917 - accuracy: 0.1167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 33s 2s/step - loss: 2198.9917 - accuracy: 0.1167 - val_loss: 2.1941 - val_accuracy: 0.1556\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 7s 574ms/step - loss: 2.2555 - accuracy: 0.0944 - val_loss: 2.2010 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 7s 563ms/step - loss: 2.2018 - accuracy: 0.1139 - val_loss: 2.1992 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.2017 - accuracy: 0.1139 - val_loss: 2.2000 - val_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1976 - accuracy: 0.0972 - val_loss: 2.1996 - val_accuracy: 0.1222\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.2046 - accuracy: 0.1389 - val_loss: 2.1997 - val_accuracy: 0.0778\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1973 - accuracy: 0.1194 - val_loss: 2.2008 - val_accuracy: 0.0778\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1966 - accuracy: 0.1194 - val_loss: 2.2013 - val_accuracy: 0.0778\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1967 - accuracy: 0.1194 - val_loss: 2.2036 - val_accuracy: 0.0778\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1964 - accuracy: 0.1111 - val_loss: 2.2051 - val_accuracy: 0.0778\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1970 - accuracy: 0.1000 - val_loss: 2.2037 - val_accuracy: 0.0778\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1962 - accuracy: 0.1139 - val_loss: 2.2060 - val_accuracy: 0.0778\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2101 - val_accuracy: 0.0778\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1964 - accuracy: 0.1194 - val_loss: 2.2120 - val_accuracy: 0.0778\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1965 - accuracy: 0.1111 - val_loss: 2.2122 - val_accuracy: 0.0778\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1962 - accuracy: 0.1083 - val_loss: 2.2093 - val_accuracy: 0.0778\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2096 - val_accuracy: 0.0778\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2122 - val_accuracy: 0.0778\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2137 - val_accuracy: 0.0778\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1970 - accuracy: 0.1194 - val_loss: 2.2154 - val_accuracy: 0.0778\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2128 - val_accuracy: 0.0778\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2130 - val_accuracy: 0.0778\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1966 - accuracy: 0.1194 - val_loss: 2.2112 - val_accuracy: 0.0778\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2105 - val_accuracy: 0.0778\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1964 - accuracy: 0.1194 - val_loss: 2.2073 - val_accuracy: 0.0778\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2095 - val_accuracy: 0.0778\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2076 - val_accuracy: 0.0778\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2081 - val_accuracy: 0.0778\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2108 - val_accuracy: 0.0778\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2097 - val_accuracy: 0.0778\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2088 - val_accuracy: 0.0778\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2081 - val_accuracy: 0.0778\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2090 - val_accuracy: 0.0778\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2087 - val_accuracy: 0.0778\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2104 - val_accuracy: 0.0778\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2075 - val_accuracy: 0.0778\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2068 - val_accuracy: 0.0778\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2091 - val_accuracy: 0.0778\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2087 - val_accuracy: 0.0778\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2069 - val_accuracy: 0.0778\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 7s 568ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2082 - val_accuracy: 0.0778\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2089 - val_accuracy: 0.0778\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2093 - val_accuracy: 0.0778\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2092 - val_accuracy: 0.0778\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2109 - val_accuracy: 0.0778\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2133 - val_accuracy: 0.0778\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2136 - val_accuracy: 0.0778\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1222 - val_loss: 2.2127 - val_accuracy: 0.0778\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2125 - val_accuracy: 0.0778\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1962 - accuracy: 0.1000 - val_loss: 2.2156 - val_accuracy: 0.0778\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2134 - val_accuracy: 0.0778\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2136 - val_accuracy: 0.0778\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2141 - val_accuracy: 0.0778\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1028 - val_loss: 2.2127 - val_accuracy: 0.0778\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1965 - accuracy: 0.1194 - val_loss: 2.2150 - val_accuracy: 0.0778\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2093 - val_accuracy: 0.0778\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2092 - val_accuracy: 0.0778\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2110 - val_accuracy: 0.0778\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2103 - val_accuracy: 0.0778\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2100 - val_accuracy: 0.0778\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2106 - val_accuracy: 0.0778\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2100 - val_accuracy: 0.0778\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2105 - val_accuracy: 0.0778\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2097 - val_accuracy: 0.0778\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 7s 563ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2099 - val_accuracy: 0.0778\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2095 - val_accuracy: 0.0778\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2080 - val_accuracy: 0.0778\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2083 - val_accuracy: 0.0778\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2081 - val_accuracy: 0.0778\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2090 - val_accuracy: 0.0778\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1961 - accuracy: 0.1083 - val_loss: 2.2103 - val_accuracy: 0.0778\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2103 - val_accuracy: 0.0778\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2110 - val_accuracy: 0.0778\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2107 - val_accuracy: 0.0778\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 7s 566ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2109 - val_accuracy: 0.0778\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 7s 565ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2113 - val_accuracy: 0.0778\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2116 - val_accuracy: 0.0778\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2115 - val_accuracy: 0.0778\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 7s 563ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2110 - val_accuracy: 0.0778\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2101 - val_accuracy: 0.0778\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2091 - val_accuracy: 0.0778\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 2.1961 - accuracy: 0.0944 - val_loss: 2.2102 - val_accuracy: 0.0778\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2107 - val_accuracy: 0.0778\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2107 - val_accuracy: 0.0778\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.2104 - val_accuracy: 0.0778\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2112 - val_accuracy: 0.0778\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 7s 536ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2104 - val_accuracy: 0.0778\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1957 - accuracy: 0.1194 - val_loss: 2.2107 - val_accuracy: 0.0778\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2102 - val_accuracy: 0.0778\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2102 - val_accuracy: 0.0778\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 7s 536ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2111 - val_accuracy: 0.0778\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2107 - val_accuracy: 0.0778\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1959 - accuracy: 0.1194 - val_loss: 2.2109 - val_accuracy: 0.0778\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2109 - val_accuracy: 0.0778\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1963 - accuracy: 0.1194 - val_loss: 2.2120 - val_accuracy: 0.0778\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 7s 534ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2108 - val_accuracy: 0.0778\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2115 - val_accuracy: 0.0778\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1960 - accuracy: 0.1194 - val_loss: 2.2123 - val_accuracy: 0.0778\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 7s 536ms/step - loss: 2.1962 - accuracy: 0.1194 - val_loss: 2.2106 - val_accuracy: 0.0778\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 7s 535ms/step - loss: 2.1961 - accuracy: 0.1194 - val_loss: 2.2094 - val_accuracy: 0.0778\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " spatial_pyramid_pooling (Sp  (None, 10752)            0         \n",
      " atialPyramidPooling)                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              44044288  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 36873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,886,857\n",
      "Trainable params: 80,886,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = make_model()\n",
    "compile_model(model)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"VGG19\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x = train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True,\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ WARNING:absl:Found untraced functions such as ... while saving. These functions will not be directly callable after loading.\n",
    ": ModelCheckpoint를 사용하는 과정에서 발견되는 오류. tf.saved_model.save 대신 model.save를 사용할 것을 권장하기 위해 출력시키는 경고라는 의견이 있음.\n",
    "(https://github.com/tensorflow/tensorflow/issues/47479#issuecomment-815314034)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 181ms/step - loss: 2.1972 - accuracy: 0.1156\n",
      "테스트 정확도: 0.116\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"VGG19\")\n",
    "print(f\"테스트 정확도: {model.evaluate(test_dataset)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 142ms/step\n",
      "15/15 [==============================] - 2s 144ms/step - loss: 2.1972 - accuracy: 0.1156\n",
      "테스트 정확도: 0.11555555462837219\n",
      "예측 라벨: [6 8 6 8 6 8 6 8 6 6 6 8 8 8 8 6 6 8 8 8 8 6 8 8 8 8 8 8 6 8 6 8 8 8 8 6 6\n",
      " 8 8 8 8 8 8 6 8 8 8 8 6 6 8 8 8 6 8 8 6 8 8 8 8 8 8 8 6 8 8 6 8 6 6 8 8 8\n",
      " 8 8 8 6 8 8 8 8 6 6 8 8 6 8 8 8 8 6 6 8 6 8 8 8 8 8 8 8 6 8 8 8 8 8 8 6 6\n",
      " 8 6 6 8 8 6 8 8 8 8 6 8 8 8 8 6 8 8 8 8 8 8 6 6 6 6 8 8 8 8 8 8 6 8 6 8 8\n",
      " 8 8 8 6 6 6 8 8 8 8 8 6 6 8 8 6 8 6 8 6 8 8 8 8 8 8 6 8 8 8 8 6 8 8 8 8 8\n",
      " 6 8 6 8 6 8 6 8 8 8 8 8 8 8 6 6 8 8 8 8 6 8 8 8 8 6 8 6 8 8 8 8 8 6 8 6 6\n",
      " 6 8 8 8 6 6 6 8 8 6 6 8 8 8 8 8 8 6 8 8 8 6 6 6 8 8 8 6 6 8 6 8 8 6 8 6 8\n",
      " 6 8 6 8 6 8 8 8 8 8 8 8 8 8 6 8 6 8 8 6 8 6 8 8 8 8 6 8 8 6 8 8 8 8 8 6 8\n",
      " 6 8 8 8 8 8 8 6 8 8 6 8 6 8 6 8 6 6 8 8 8 8 8 8 8 8 8 8 6 8 8 8 6 6 8 8 8\n",
      " 8 8 8 8 8 6 8 8 6 8 6 8 8 8 8 8 8 8 6 8 6 8 8 6 8 8 8 8 6 8 8 6 6 6 6 6 6\n",
      " 6 6 6 8 6 8 8 8 8 6 6 8 6 6 6 6 6 8 6 6 8 8 8 8 8 8 6 8 6 8 8 8 8 8 8 8 8\n",
      " 8 8 6 8 6 8 8 6 6 8 8 8 6 8 8 8 8 8 8 8 8 8 8 8 6 6 6 8 6 8 8 6 6 8 8 8 8\n",
      " 8 8 6 8 8 8]\n",
      "15/15 [==============================] - 2s 142ms/step\n",
      "예측 정도: [[0.11222447 0.11031617 0.10945442 ... 0.11440634 0.10821518 0.1144456 ]\n",
      " [0.1122049  0.1104444  0.10987205 ... 0.11375342 0.10880906 0.11375288]\n",
      " [0.11222868 0.11018997 0.10898    ... 0.11488562 0.10759962 0.11495508]\n",
      " ...\n",
      " [0.11222729 0.11028314 0.10931073 ... 0.11456582 0.10801302 0.11462808]\n",
      " [0.11228258 0.11021734 0.10936578 ... 0.11477389 0.10789374 0.11482041]\n",
      " [0.11224973 0.11007147 0.10869782 ... 0.1154443  0.10713837 0.11561371]]\n",
      "450 data are predicted.\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(test_dataset)\n",
    "predicted_labels = y_predict.argmax(axis=-1)\n",
    "print(f\"테스트 정확도: {model.evaluate(test_dataset)[1]}\")\n",
    "print(f\"예측 라벨: {predicted_labels}\")\n",
    "print(f\"예측 정도: {model.predict(test_dataset)}\")\n",
    "print(f\"{len(predicted_labels)} data are predicted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('c_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad49a3e310a1b80e3d37ec823c88e1d3b8d0e81fa400ebb92324267753db291b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
